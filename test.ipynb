{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m8d809b5da21a       \u001b[m  Tue Aug 16 08:00:55 2022  \u001b[1m\u001b[30m460.73.01\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 67'C\u001b[m, \u001b[1m\u001b[32m 94 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m11538\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    8\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 44'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10325\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[1m\u001b[32m 54 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m15031\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 54'C\u001b[m, \u001b[1m\u001b[32m 63 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1761\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 56'C\u001b[m, \u001b[1m\u001b[32m 88 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m23739\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 55'C\u001b[m, \u001b[1m\u001b[32m 94 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m23739\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1305\u001b[m / \u001b[33m24268\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_gpus = [1, 7]\n",
    "dev = None if len(available_gpus) == 0 else available_gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x, k):\n",
    "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
    "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
    "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
    "    # (batch_size, num_points, k)\n",
    "    idx = pairwise_distance.topk(k=k, dim=-1)[1]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def get_graph_feature(x, k, knn_only=False, disp_only=False):\n",
    "    batch_size = x.size(0)\n",
    "    num_points = x.size(2)\n",
    "    x = x.view(batch_size, -1, num_points)\n",
    "    idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
    "    device = x.get_device()\n",
    "    idx_base = torch.arange(0, batch_size).view(-1, 1, 1) * num_points\n",
    "    idx_base = idx_base.cuda(device)\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.view(-1)\n",
    "    _, num_dims, _ = x.size()\n",
    "    # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
    "    x = x.transpose(2, 1).contiguous()\n",
    "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
    "    if knn_only:\n",
    "        return feature\n",
    "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
    "    if disp_only:\n",
    "        return (feature - x).permute(0, 3, 1, 2)\n",
    "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature      # (batch_size, 2*num_dims, num_points, k)\n",
    "\n",
    "\n",
    "class Transform_Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Transform_Net, self).__init__()\n",
    "\n",
    "        self.k = args.k\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn1,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, bias=False),\n",
    "                                   self.bn2,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1, bias=False),\n",
    "                                   self.bn3,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "        self.linear1 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.linear2 = nn.Linear(512, 256, bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.transform = nn.Linear(256, 3*3)\n",
    "        nn.init.constant_(self.transform.weight, 0)\n",
    "        nn.init.eye_(self.transform.bias.view(3, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B x 3 x N)\n",
    "        batch_size = x.size(0)\n",
    "        # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n",
    "        t = get_graph_feature(x, k=self.k)\n",
    "\n",
    "        # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        t = self.conv1(t)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 128, num_points, k)\n",
    "        t = self.conv2(t)\n",
    "        # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)\n",
    "        t = t.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 128, num_points) -> (batch_size, 1024, num_points)\n",
    "        t = self.conv3(t)\n",
    "        # (batch_size, 1024, num_points) -> (batch_size, 1024)\n",
    "        t = t.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 1024) -> (batch_size, 512)\n",
    "        t = F.leaky_relu(self.bn4(self.linear1(t)), negative_slope=0.2)\n",
    "        # (batch_size, 512) -> (batch_size, 256)\n",
    "        t = F.leaky_relu(self.bn5(self.linear2(t)), negative_slope=0.2)\n",
    "\n",
    "        # (batch_size, 256) -> (batch_size, 3*3)\n",
    "        t = self.transform(t)\n",
    "        # (batch_size, 3*3) -> (batch_size, 3, 3)\n",
    "        t = t.view(batch_size, 3, 3)\n",
    "\n",
    "        # (batch_size, 3, num_points) -> (batch_size, num_points, 3)\n",
    "        x = x.transpose(2, 1)\n",
    "        # (batch_size, num_points, 3) * (batch_size, 3, 3) -> (batch_size, num_points, 3)\n",
    "        x = torch.bmm(x, t)\n",
    "        # (batch_size, num_points, 3) -> (batch_size, 3, num_points)\n",
    "        x = x.transpose(2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DGCNN_partseg(nn.Module):\n",
    "    def __init__(self, args, seg_num_all):\n",
    "        super(DGCNN_partseg, self).__init__()\n",
    "        self.args = args\n",
    "        self.seg_num_all = seg_num_all\n",
    "        self.tnet = Transform_Net(args)\n",
    "        self.k = args.k\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.bn6 = nn.BatchNorm1d(args.emb_dims)\n",
    "        self.bn7 = nn.BatchNorm1d(64)\n",
    "        self.bn8 = nn.BatchNorm1d(256)\n",
    "        self.bn9 = nn.BatchNorm1d(256)\n",
    "        self.bn10 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn1,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn2,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn3,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn4,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn5,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv6 = nn.Sequential(nn.Conv1d(192, args.emb_dims, kernel_size=1, bias=False),\n",
    "                                   self.bn6,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv7 = nn.Sequential(nn.Conv1d(16, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn7,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv8 = nn.Sequential(nn.Conv1d(1280, 256, kernel_size=1, bias=False),\n",
    "                                   self.bn8,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.dp1 = nn.Dropout(p=args.dropout)\n",
    "        self.conv9 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=1, bias=False),\n",
    "                                   self.bn9,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.dp2 = nn.Dropout(p=args.dropout)\n",
    "        self.conv10 = nn.Sequential(nn.Conv1d(256, 128, kernel_size=1, bias=False),\n",
    "                                    self.bn10,\n",
    "                                    nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv11 = nn.Conv1d(128, self.seg_num_all,\n",
    "                                kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x, l):\n",
    "        batch_size = x.size(0)\n",
    "        num_points = x.size(2)\n",
    "\n",
    "        x = self.tnet(x)\n",
    "\n",
    "        # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n",
    "        x = get_graph_feature(x, k=self.k)\n",
    "        # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv1(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv2(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = get_graph_feature(x1, k=self.k)\n",
    "        # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv3(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv4(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = get_graph_feature(x2, k=self.k)\n",
    "        # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv5(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64*3, num_points)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "\n",
    "        # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)\n",
    "        x = self.conv6(x)\n",
    "        # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims, 1)\n",
    "        x = x.max(dim=-1, keepdim=True)[0]\n",
    "\n",
    "        # (batch_size, num_categoties, 1)\n",
    "        l = l.view(batch_size, -1, 1)\n",
    "        # (batch_size, num_categoties, 1) -> (batch_size, 64, 1)\n",
    "        l = self.conv7(l)\n",
    "\n",
    "        x = torch.cat((x, l), dim=1)            # (batch_size, 1088, 1)\n",
    "        # (batch_size, 1088, num_points)\n",
    "        x = x.repeat(1, 1, num_points)\n",
    "\n",
    "        # (batch_size, 1088+64*3, num_points)\n",
    "        x = torch.cat((x, x1, x2, x3), dim=1)\n",
    "\n",
    "        # (batch_size, 1088+64*3, num_points) -> (batch_size, 256, num_points)\n",
    "        x = self.conv8(x)\n",
    "        x = self.dp1(x)\n",
    "        # (batch_size, 256, num_points) -> (batch_size, 256, num_points)\n",
    "        x = self.conv9(x)\n",
    "        x = self.dp2(x)\n",
    "        # (batch_size, 256, num_points) -> (batch_size, 128, num_points)\n",
    "        x = self.conv10(x)\n",
    "        # (batch_size, 256, num_points) -> (batch_size, seg_num_all, num_points)\n",
    "        x = self.conv11(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, k, emb_dim):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.k = k\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv6 = nn.Sequential(nn.Conv1d(192, emb_dim, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm1d(emb_dim),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        num_points = x.size(2)\n",
    "\n",
    "        # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n",
    "        x = get_graph_feature(x, k=self.k)\n",
    "        # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv1(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv2(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = get_graph_feature(x1, k=self.k)\n",
    "        # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv3(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv4(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = get_graph_feature(x2, k=self.k)\n",
    "        # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x = self.conv5(x)\n",
    "        # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
    "\n",
    "        # (batch_size, 64*3, num_points)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)\n",
    "        x = self.conv6(x)\n",
    "        # (batch_size, num_points, emb_dims)\n",
    "        y = x.view(batch_size, num_points, self.emb_dim)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "d = {\n",
    "    'k': 40,\n",
    "    'emb_dims': 1024,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "args = dotdict(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = DGCNN_partseg(args, seg_num_all=50).cuda(dev)\n",
    "model_old_dist = nn.DataParallel(model_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old_dist.load_state_dict(torch.load(\"outputs/partseg/models/dgcnn.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DGCNN(k=40, emb_dim=1024).cuda(dev)\n",
    "model.load_state_dict(torch.load('ckpts/dgcnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_layer = list(list(model_old_dist.children())[0].children())[16][0].weight\n",
    "new_layer = list(model.children())[5][0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(\n",
    "    to_numpy(new_layer), to_numpy(original_layer), rtol=1e-03, atol=1e-05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
